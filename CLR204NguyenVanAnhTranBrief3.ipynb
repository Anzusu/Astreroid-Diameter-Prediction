{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "urlretrieve(\"https://raw.githubusercontent.com/blakelobato/Predicting-Asteroid-Diameter-Dash/master/model/Pred_Ast_Diam_2.csv\",\"Pred_Ast_Diam_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "plt.figure()\n",
    "df = pd.read_csv(\"Pred_Ast_Diam_2.csv\")\n",
    "df = df.fillna(np.nan,axis=0)\n",
    "print(df.shape)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "df.profile_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram Plot of target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the target variable\n",
    "plt.figure()\n",
    "sns.histplot(df.diameter)\n",
    "plt.savefig(\"Histogram.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring all the missing values have been taken care of previously \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of the different means, distributions, and values associated with the features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at possibly doing a time split for this data\n",
    "df.first_year_obs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with splitting the data into a train, validation, and test case using an 80/20 split.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split into Train and Test sets\n",
    "train, test = train_test_split(df, train_size=.80, test_size=0.20, random_state=42)\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "train.shape, val.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an idea of what the train dataframe now looks like (random selection of rows from the original dataframe)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns are the features we are using \n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder to myself which columns are categorical and numeric\n",
    "features = ['orbit_id', 'e', 'a', 'i', 'om', 'w', 'ma', 'n', 'tp', 'moid','moid_jup', 'class', 'producer', 'data_arc', 'n_obs_used', 'rms','diameter', 'albedo', 'diameter_sigma', 'first_year_obs','first_month_obs', 'last_obs_year', 'last_obs_month']\n",
    "numeric_cols = ['e', 'a', 'i', 'om', 'w', 'ma', 'n', 'tp', 'moid','moid_jup', 'data_arc', 'n_obs_used', 'rms','diameter', 'albedo', 'diameter_sigma', 'first_year_obs','first_month_obs', 'last_obs_year', 'last_obs_month']\n",
    "#categorical_cols = ['orbit_id, 'class', 'producer']\n",
    "target = 'diameter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation HeatMap (see attached png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "heatmap = sns.heatmap(df.corr(numeric_only=True), vmin=1, vmax=-1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\n",
    "plt.savefig('myplot.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplots (see attached png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='a', \n",
    "    y='diameter')\n",
    "plt.title('Scatterplot Between Asteroid Diameter and Semimajor Axis')\n",
    "plt.xlabel('Semi-major Axis')\n",
    "plt.ylabel('Diameter')\n",
    "plt.savefig('Scatterplot Between Asteroid Diameter and Semimajor Axis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='e', \n",
    "    y='diameter')\n",
    "plt.title('Scatterplot Between Asteroid Diameter and Eccentricity')\n",
    "plt.xlabel('Eccentricity')\n",
    "plt.ylabel('Diameter')\n",
    "plt.savefig('Scatterplot Between Asteroid Diameter and Eccentricity.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='n_obs_used', \n",
    "    y='diameter')\n",
    "plt.title('Scatterplot Between Asteroid Diameter and Number of Observations Used')\n",
    "plt.xlabel('Number of Observations Used')\n",
    "plt.ylabel('Diameter')\n",
    "plt.savefig('Scatterplot Between Asteroid Diameter and Number of Observations Used.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Arrange y target vectors\n",
    "target = 'diameter'\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "y_test = test[target]\n",
    "\n",
    "# Get mean baseline\n",
    "print('Mean Baseline (using 0 features)')\n",
    "guess = y_train.mean()\n",
    "\n",
    "# Train Error\n",
    "y_pred = [guess] * len(y_train)\n",
    "mae_t = mean_absolute_error(y_train, y_pred)\n",
    "mse_t = mean_squared_error(y_train, y_pred)\n",
    "rmse_t = math.sqrt(mse_t)\n",
    "r2_t = r2_score(y_train, y_pred)\n",
    "print(f'Training MAE Error: {mae_t:.2f} km standarized')\n",
    "print(f'Training MSE Error: {mse_t:.2f} km standarized')\n",
    "print(f'Validation RMSE Error: {rmse_t:.2f} km standarized')\n",
    "print(f'Training R^2 Error: {r2_t:.2f}%')\n",
    "\n",
    "# Validation Error\n",
    "y_pred = [guess] * len(y_val)\n",
    "mae_v = mean_absolute_error(y_val, y_pred)\n",
    "mse_v = mean_squared_error(y_val, y_pred)\n",
    "rmse_v = math.sqrt(mse_v)\n",
    "r2_val = r2_score(y_val, y_pred)\n",
    "print(f'Validation MAE Error: {mae_v:.2f} km standarized ')\n",
    "print(f'Validation MSE Error: {mse_v:.2f} km standarized')\n",
    "print(f'Validation RMSE Error: {rmse_v:.2f} km standarized')\n",
    "print(f'Validation R^2 Error: {r2_val:.2f}%')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#1. Import the appropriate estimator class from Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 2. Instantiate this class\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. Arrange X features matrices (already did y target vectors)\n",
    "featurelr = ['n_obs_used']\n",
    "X_train = train[featurelr]\n",
    "X_val = val[featurelr]\n",
    "X_test = test[featurelr]\n",
    "print(f'Linear Regression, dependent on {featurelr}:')\n",
    "\n",
    "# 4. Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_t = model.predict(X_train)\n",
    "mae_t = mean_absolute_error(y_train, y_pred_t)\n",
    "mse_t = mean_squared_error(y_train, y_pred_t)\n",
    "rmse_t = math.sqrt(mse_t)\n",
    "r2_t = r2_score(y_train, y_pred_t)\n",
    "print(f'Training MAE Error: {mae_t:.2f} km standarized')\n",
    "print(f'Training MSE Error: {mse_t:.2f} km standarized')\n",
    "print(f'Training RMSE Error: {mse_t:.2f} km standarized')\n",
    "print(f'Training R^2 Error: {r2_t:.4f}')\n",
    "\n",
    "# 5. Apply the model to new data\n",
    "y_pred_v = model.predict(X_val)\n",
    "mae_v = mean_absolute_error(y_val, y_pred_v)\n",
    "mse_v = mean_squared_error(y_val, y_pred_v)\n",
    "rmse_v = math.sqrt(mse_v)\n",
    "r2_val = r2_score(y_val, y_pred_v)\n",
    "print(f'Validation MAE Error: {mae_v:.2f} km standarized ')\n",
    "print(f'Validation MSE Error: {mse_v:.2f} km standarized')\n",
    "print(f'Training RMSE Error: {mse_v:.2f} km standarized')\n",
    "print(f'Validation R^2 Error: {r2_val:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "#from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "features = ['orbit_id', 'e', 'a', 'i', 'om', 'w', 'ma', 'n', 'tp', 'moid','moid_jup', 'class', 'producer', 'data_arc', 'n_obs_used', 'rms','diameter', 'albedo', 'diameter_sigma', 'first_year_obs','first_month_obs', 'last_obs_year', 'last_obs_month']\n",
    "target = 'diameter'\n",
    "\n",
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "X_train = train.drop(columns=target)\n",
    "X_val = val.drop(columns=target)\n",
    "\n",
    "# Create a pipeline, one hot encode the low cardinality values, ordinal encode the higher cardinalaity, scale everythgin, run deceison tree regression\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True, cols=['class','producer']), \n",
    "    ce.OrdinalEncoder(cols = ['orbit_id']),\n",
    "    StandardScaler(),\n",
    "    DecisionTreeRegressor(criterion='friedman_mse', max_depth=15, min_samples_leaf=15, min_samples_split=4, random_state=42)\n",
    ")\n",
    "\n",
    "# fit the pipeline on training data\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "\n",
    "print('- Training R^2 value', pipeline.score(X_train, y_train))\n",
    "print('- Validation R^2 value', pipeline.score(X_val, y_val))\n",
    "print(f'- Training MAE: {mean_absolute_error(y_train,y_pred_train)} km (standarized)')\n",
    "print(f'- Validation MAE: {mean_absolute_error(y_val,y_pred_val)} km (standarized)')\n",
    "print(f'- Training MSE: {mean_squared_error(y_train,y_pred_train)} km (standarized)')\n",
    "print(f'- Validation MSE: {mean_squared_error(y_val,y_pred_val)} km (standarized)')\n",
    "print(f'- Training RMSE: {math.sqrt(mean_squared_error(y_train,y_pred_train))} km (standarized)')\n",
    "print(f'- Validation RMSE: {math.sqrt(mean_squared_error(y_val,y_pred_val))} km (standarized)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperoptimisation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "features = ['orbit_id', 'e', 'a', 'i', 'om', 'w', 'ma', 'n', 'tp', 'moid','moid_jup', 'class', 'producer', 'data_arc', 'n_obs_used', 'rms','diameter', 'albedo', 'diameter_sigma', 'first_year_obs','first_month_obs', 'last_obs_year', 'last_obs_month']\n",
    "target = 'diameter'\n",
    "X_train = train[features]\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True, cols=['class','producer']), \n",
    "    ce.OrdinalEncoder(cols = ['orbit_id']),\n",
    "    StandardScaler(),\n",
    "    DecisionTreeRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "#different parameter distributions to test for the best possible combination\n",
    "param_distributions = {\n",
    "   'decisiontreeregressor__min_samples_leaf': [1, 3, 5, 7, 9, 10, 15], \n",
    "    'decisiontreeregressor__max_depth': [5, 7, 9, 10, 13, 15, 17, 20, 21,  25, 30], \n",
    "    'decisiontreeregressor__min_samples_split': [2, 3, 4, 5, 7],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# If you're on Colab, decrease n_iter & cv parameters\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation MAE', -search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphing Decision Tree (hyperoptimisation was trialed and error based on hyperoptimisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import os\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"D:\\Graphviz\\bin\"\n",
    "ord_encoder = ce.OrdinalEncoder(cols = ['orbit_id'])\n",
    "X_train_ordencoded = ord_encoder.fit_transform(X_train)\n",
    "X_val_ordencoded = ord_encoder.transform(X_val)\n",
    "\n",
    "oh_encoder = ce.OneHotEncoder(use_cat_names=True, cols=['class','producer'])\n",
    "X_train_encoded = oh_encoder.fit_transform(X_train_ordencoded)\n",
    "X_val_encoded = oh_encoder.transform(X_val_ordencoded)\n",
    "\n",
    "dt = pipeline.named_steps['decisiontreeregressor']\n",
    "\n",
    "dt.fit(X_train_encoded,y_train)\n",
    "\n",
    "encoded_columns = X_train_encoded.columns\n",
    "\n",
    "dot_data = export_graphviz(dt, \n",
    "                           out_file=None, \n",
    "                           max_depth=7, \n",
    "                           feature_names=encoded_columns,\n",
    "                           impurity=False, \n",
    "                           filled=True, \n",
    "                           proportion=True, \n",
    "                           rounded=True)   \n",
    "display(graphviz.Source(dot_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "features = ['orbit_id', 'e', 'a', 'i', 'om', 'w', 'ma', 'n', 'tp', 'moid','moid_jup', 'class', 'producer', 'data_arc', 'n_obs_used', 'rms','diameter', 'albedo', 'diameter_sigma', 'first_year_obs','first_month_obs', 'last_obs_year', 'last_obs_month']\n",
    "target = 'diameter'\n",
    "\n",
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "X_train = train.drop(columns=target)\n",
    "X_val = val.drop(columns=target)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True, cols=['class','producer']), \n",
    "    ce.OrdinalEncoder(cols = ['orbit_id']),\n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor(n_estimators=450, max_depth=None, max_features=.77, min_samples_leaf=3, min_samples_split=3,  n_jobs=-1, random_state=42)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "print('Training R^2 value', pipeline.score(X_train, y_train))\n",
    "print('Validation R^2 value', pipeline.score(X_val, y_val))\n",
    "print(f'Training MAE: {mean_absolute_error(y_train,y_pred_train)} km (standarized)')\n",
    "print(f'Validation MAE: {mean_absolute_error(y_val,y_pred_val)} km (standarized)')\n",
    "print(f'Training MSE: {mean_squared_error(y_train,y_pred_train)} km (standarized)')\n",
    "print(f'Validation MSE: {mean_squared_error(y_val,y_pred_val)} km (standarized)')\n",
    "print(f'Training RMSE: {math.sqrt(mean_squared_error(y_train,y_pred_train))} km (standarized)')\n",
    "print(f'Validation RMSE: {math.sqrt(mean_squared_error(y_val,y_pred_val))} km (standarized)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'diameter'\n",
    "features = train.columns.drop('diameter')\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols = ['orbit_id'])\n",
    "X_train_ordencoded = ord_encoder.fit_transform(X_train)\n",
    "X_val_ordencoded = ord_encoder.transform(X_val)\n",
    "X_test_ordencoded = ord_encoder.transform(X_test)\n",
    "\n",
    "oh_encoder = ce.OneHotEncoder(use_cat_names=True, cols=['class','producer'])\n",
    "X_train_encoded = oh_encoder.fit_transform(X_train_ordencoded)\n",
    "X_val_encoded = oh_encoder.transform(X_val_ordencoded)\n",
    "X_test_encoded = oh_encoder.transform(X_test_ordencoded)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_encoded)\n",
    "scaler.fit(X_val_encoded)\n",
    "scaler.fit(X_test_encoded)\n",
    "\n",
    "model_dt_shap = DecisionTreeRegressor(criterion='friedman_mse', max_depth=15, min_samples_leaf=15, min_samples_split=4, random_state=42)\n",
    "\n",
    "\n",
    "model_dt_shap.fit(X_train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(model_dt_shap)\n",
    "shap_values = explainer.shap_values(X_test_encoded)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapley Plot for Astreroid Prediction (see attached png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test_encoded)\n",
    "plt.savefig(\"Shapley.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally matplotlib was not supporting the graphs so I could not display them. I decided to save it as a png that is attached to my assessment instead. However it seems to be working now but I will leave the plots as they are, saved to the document just incase there is anything wrong with the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
